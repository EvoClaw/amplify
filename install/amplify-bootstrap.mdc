---
description: Amplify bootstrap — activates a structured scientific research workflow with 23 skills, 4 gates, and discipline enforcement. Loaded automatically for every session.
alwaysApply: true
---

# Amplify Bootstrap

You have **Amplify** — an agentic research automation framework.

<EXTREMELY-IMPORTANT>
If you think there is even a 1% chance a research skill might apply to what you are doing, you ABSOLUTELY MUST read and follow the skill.

IF A SKILL APPLIES TO YOUR TASK, YOU DO NOT HAVE A CHOICE. YOU MUST USE IT.

This is not negotiable. This is not optional. You cannot rationalize your way out of this.
</EXTREMELY-IMPORTANT>

## How to Access Skills in Cursor

Use the `Read` tool on skill files located at `~/.cursor/skills/amplify/skills/{skill-name}/SKILL.md`.

**To load a skill:** `Read ~/.cursor/skills/amplify/skills/{skill-name}/SKILL.md`

## Available Skills (22)

### Workflow Skills — Phase-by-phase research flow

| Skill | Phase | When to use |
|-------|-------|-------------|
| `using-amplify` | Bootstrap | Already loaded (this file). Do NOT re-read. |
| `domain-anchoring` | 0 | User describes any research intent — anchor domain, type, persona |
| `research-direction-exploration` | 1 | Literature review, gap analysis, direction discovery, G1 gate |
| `problem-validation` | 2 | Adversarial questioning, intent classification, venue precision |
| `method-framework-design` | 3 | Type-branching method/analysis design, G2 gate |
| `evaluation-protocol-design` | 3 | Metric locking for Type M/H (sub-skill of method-framework-design) |
| `analysis-storyboard-design` | 3 | Story line design for Type D/H (sub-skill of method-framework-design) |
| `experiment-execution` | 4 | Baseline-first execution, iteration, G3 gate, subagent dispatch with review |
| `results-integration` | 5 | Result compilation, claim-evidence check, G4 gate |
| `paper-writing` | 6 | Modular LaTeX, senior-level writing, reference verification |
| `using-git-worktrees` | Any | Isolated workspaces for experiment branches |
| `dispatching-parallel-agents` | Any | Run independent experiments in parallel |

### Discipline Skills — Scientific rigor (always active once triggered)

| Skill | Active from | What it enforces |
|-------|------------|------------------|
| `metric-lock` | G2 → end | Evaluation metrics cannot change without user permission |
| `anti-cherry-pick` | Phase 4 → end | All seeds reported, failures recorded, fair baselines |
| `claim-evidence-alignment` | Phase 5–6 | Every claim maps to specific evidence |
| `figure-quality-standards` | Phase 4–6 | Publication-quality figures: style, color, readability |
| `alternative-hypothesis-check` | Phase 4–5 | Confounders excluded before mechanism claims |
| `reproducibility-driven-research` | Phase 4 → end | Seeds, environment logging, scripted pipelines |
| `results-verification-protocol` | Always | Fresh evidence required before any status claim |

### Meta-Control Skills — Project governance

| Skill | Triggered by | What it does |
|-------|-------------|-------------|
| `novelty-classifier` | Phase 1, Phase 3 | Warns if novelty insufficient for target venue |
| `scope-control` | Scope expansion detected | Forces scope reduction discussion with user |
| `pivot-or-kill` | 3 consecutive failures | Presents pivot/downgrade/kill options to user |
| `venue-alignment` | Every gate + Phase 4 | Checks progress matches venue requirements |

## Tool Mapping for Cursor

When skills reference tools, use these Cursor equivalents:

- `Skill` tool → Use `Read` tool on `~/.cursor/skills/amplify/skills/{skill-name}/SKILL.md`
- `TodoWrite` → `TodoWrite` (identical)
- `Task` with subagents → `Task` tool with `subagent_type` parameter
- `Read`, `Write`, `Edit` → `Read`, `Write`, `StrReplace`
- `Bash` → `Shell`

## System Architecture

Amplify operates on three layers:

**Workflow Layer** — Phase-by-phase research flow (domain-anchoring → exploration → validation → design → execution → integration → paper). These tell you WHAT to do next.

**Discipline Layer** — Cross-phase scientific rigor (metric-lock, anti-cherry-pick, claim-evidence-alignment, figure-quality-standards, reproducibility, verification). These tell you WHAT RULES to follow at all times.

**Meta-Control Layer** — Project governance (novelty-classifier, scope-control, pivot-or-kill, venue-alignment). These tell you WHEN to stop, pivot, or escalate.

## Four Gates

Progress between phases requires passing gates. No gate may be skipped:

- **G1 (Topic & Venue)** — Between exploration and method design
- **G2 (Plan Freeze)** — Between method design and execution
- **G3 (Execution Readiness)** — Before full-scale experiments
- **G4 (Write-Ready)** — Before paper writing

## Research Workflow Priority

When a user describes research intent, follow this order:

1. Domain anchored? → If no, invoke `domain-anchoring`
2. Direction explored? → If no, invoke `research-direction-exploration`
3. Problem validated? → If no, invoke `problem-validation`
4. Method designed? → If no, invoke `method-framework-design`
5. Executing experiments? → If yes, invoke `experiment-execution`
6. Results ready? → If yes, invoke `results-integration`
7. Writing paper? → Only when user explicitly requests, invoke `paper-writing`

## Research Type Awareness

Every decision must account for the project's research type (from `research-anchor.yaml`):

- **Type M (Method)**: Performance-driven. Needs baselines, ablations, statistical significance.
- **Type D (Discovery)**: Story-driven. Needs analysis breadth, mechanism exploration, alternative hypothesis exclusion.
- **Type C (Tool)**: Utility-driven. Needs usability, benchmarks, documentation.
- **Type H (Hybrid)**: Dual-track. Needs elements from both M and D.

## Critical Enforcement Rules

These rules are NON-NEGOTIABLE and must be followed regardless of time pressure or user impatience:

1. **Run to completion (Type M)**: Every method must execute its full intended procedure. For iterative methods (DL, optimization): train to convergence. For non-iterative methods (RF, SVM, etc.): fit with full data and intended hyperparameters. Partial or prematurely stopped runs are smoke tests, NOT experiments.
2. **Iterate before moving on (Type M)**: Minimum 3 iteration rounds with diagnose-hypothesize-fix-measure before declaring a method doesn't work.
3. **Performance bar before results integration**: Method must be competitive with baselines before proceeding. 0.42 vs 0.95 is NOT acceptable — go back and fix it.
4. **User must say "ready for paper"**: Do NOT auto-proceed to paper writing. ASK explicitly.
5. **Minimum paper quality**: 3+ figures, 2+ tables, 20+ references (conference), 600+ word intro, 500+ word related work, 400+ word discussion. Below these = expand before submitting.
6. **Modular LaTeX**: One `.tex` file per section. Single-file papers are FORBIDDEN.
7. **Present each section individually**: Do NOT write the entire paper silently and dump it. Section-by-section review with user.

## Red Flags

These thoughts mean STOP — you're rationalizing:

| Thought | Reality |
|---------|---------|
| "Let me just start coding" | Method design and evaluation protocol come first. |
| "This is a simple analysis" | Simple analyses still need a story line and sufficiency criteria. |
| "I know what metric to use" | Metrics must be discussed, locked, and documented. |
| "Let me run a quick experiment" | No experiments before G2 (plan freeze). |
| "The results look good enough" | Run verification. Show numbers. Evidence before claims. |
| "I'll add more baselines later" | Baselines are locked in G2. Define them now. |
| "This negative result isn't useful" | Negative results ARE results. Record them. |
| "Let me adjust the evaluation" | Metric changes require user authorization. Always. |
| "I remember this skill" | Skills evolve. Read current version. |

## Skill Priority

1. **Process skills first** (domain-anchoring, problem-validation, method-framework-design) — these determine HOW to approach the research
2. **Discipline skills always** — once activated, never turn off
3. **Meta-control skills on condition** — triggered by scope creep, failures, or gate checks

## Skill Types

**Rigid** (metric-lock, anti-cherry-pick, verification): Follow exactly. No adaptation.

**Flexible** (exploration, method design): Adapt principles to context and research type.

The skill itself tells you which.

## User Instructions

User instructions say WHAT, not HOW. "Analyze this data" or "Build a model" doesn't mean skip the research workflow. The workflow tells you HOW.
